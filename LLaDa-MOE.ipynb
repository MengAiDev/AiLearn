{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport numpy as np\nimport torch.nn.functional as F\n\nfrom transformers import AutoTokenizer, AutoModel\n\n\ndef add_gumbel_noise(logits, temperature):\n    if temperature == 0:\n        return logits\n    logits = logits.to(torch.float64)\n    noise = torch.rand_like(logits, dtype=torch.float64)\n    gumbel_noise = (- torch.log(noise)) ** temperature\n    return logits.exp() / gumbel_noise\n\n\ndef get_num_transfer_tokens(mask_index, steps):\n    mask_num = mask_index.sum(dim=1, keepdim=True)\n\n    base = mask_num // steps\n    remainder = mask_num % steps\n\n    num_transfer_tokens = torch.zeros(mask_num.size(0), steps, device=mask_index.device, dtype=torch.int64) + base\n\n    for i in range(mask_num.size(0)):\n        num_transfer_tokens[i, :remainder[i]] += 1\n\n    return num_transfer_tokens\n\n\n@ torch.no_grad()\ndef generate(model, prompt, steps=128, gen_length=128, block_length=128, temperature=0.,\n             cfg_scale=0., remasking='low_confidence', mask_id=156895):\n    x = torch.full((1, prompt.shape[1] + gen_length), mask_id, dtype=torch.long).to(model.device)\n    x[:, :prompt.shape[1]] = prompt.clone()\n    prompt_index = (x != mask_id)\n\n    assert gen_length % block_length == 0\n    num_blocks = gen_length // block_length\n    assert steps % num_blocks == 0\n    steps = steps // num_blocks\n\n    for num_block in range(num_blocks):\n        block_mask_index = (x[:, prompt.shape[1] + num_block * block_length: prompt.shape[1] + (num_block + 1) * block_length:] == mask_id)\n        num_transfer_tokens = get_num_transfer_tokens(block_mask_index, steps)\n        for i in range(steps):\n            mask_index = (x == mask_id)\n            if cfg_scale > 0.:\n                un_x = x.clone()\n                un_x[prompt_index] = mask_id\n                x_ = torch.cat([x, un_x], dim=0)\n                logits = model(x_).logits\n                logits, un_logits = torch.chunk(logits, 2, dim=0)\n                logits = un_logits + (cfg_scale + 1) * (logits - un_logits)\n            else:\n                logits = model(x).logits\n\n            logits_with_noise = add_gumbel_noise(logits, temperature=temperature)\n            x0 = torch.argmax(logits_with_noise, dim=-1) # b, l\n\n            if remasking == 'low_confidence':\n                p = F.softmax(logits, dim=-1)\n                x0_p = torch.squeeze(\n                    torch.gather(p, dim=-1, index=torch.unsqueeze(x0, -1)), -1) # b, l\n            elif remasking == 'random':\n                x0_p = torch.rand((x0.shape[0], x0.shape[1]), device=x0.device)\n            else:\n                raise NotImplementedError(remasking)\n\n            x0_p[:, prompt.shape[1] + (num_block + 1) * block_length:] = -np.inf\n\n            x0 = torch.where(mask_index, x0, x)\n            confidence = torch.where(mask_index, x0_p, -np.inf)\n\n            transfer_index = torch.zeros_like(x0, dtype=torch.bool, device=x0.device)\n            for j in range(confidence.shape[0]):\n                _, select_index = torch.topk(confidence[j], k=num_transfer_tokens[j, i])\n                transfer_index[j, select_index] = True\n            x[transfer_index] = x0[transfer_index]\n\n    return x\n\n\ndevice = 'cuda'\nmodel = AutoModel.from_pretrained('inclusionAI/LLaDA-MoE-7B-A1B-Instruct', trust_remote_code=True, torch_dtype=torch.bfloat16).to(device).eval()\ntokenizer = AutoTokenizer.from_pretrained('inclusionAI/LLaDA-MoE-7B-A1B-Instruct', trust_remote_code=True)\n\nprompt = \"Lily can run 12 kilometers per hour for 4 hours. After that, she runs 6 kilometers per hour. How many kilometers can she run in 8 hours?\"\nm = [\n    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n    {\"role\": \"user\", \"content\": prompt}\n]\nprompt = tokenizer.apply_chat_template(m, add_generation_prompt=True, tokenize=False)\n\ninput_ids = tokenizer(prompt)['input_ids']\ninput_ids = torch.tensor(input_ids).to(device).unsqueeze(0)\n\ntext = generate(model, input_ids, steps=128, gen_length=128, block_length=32, temperature=0., cfg_scale=0., remasking='low_confidence')\nprint(tokenizer.batch_decode(text[:, input_ids.shape[1]:], skip_special_tokens=False)[0])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}